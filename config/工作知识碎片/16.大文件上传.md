---
description: è¯¥æ–‡è¯¦ç»†æè¿°çš„å¤§æ–‡ä»¶ä¸Šä¼ çš„æ€è·¯ï¼Œçœ‹å®Œä¿è¯ä½ é†é†çŒé¡¶ï¼Œä»Žæ­¤ä¸å†æƒ§æ€•
tags:
	- éš¾ç‚¹
categories:
	- å·¥ä½œæ¡ˆä¾‹
---
# å¤§æ–‡ä»¶ä¸Šä¼ 

## åˆ†ç‰‡ä¸Šä¼ 

### web worker

[Web Worker ä¸º Web å†…å®¹åœ¨åŽå°çº¿ç¨‹ä¸­è¿è¡Œè„šæœ¬æä¾›äº†ä¸€ç§ç®€å•çš„æ–¹æ³•ã€‚çº¿ç¨‹å¯ä»¥æ‰§è¡Œä»»åŠ¡è€Œä¸å¹²æ‰°ç”¨æˆ·ç•Œé¢ã€‚](https://developer.mozilla.org/zh-CN/docs/Web/API/Web_Workers_API/Using_web_workers)è¿™æ˜¯MDNå¯¹äºŽWeb Workerçš„æè¿°ã€‚ç®€å•æ¥è¯´å°±æ˜¯ä¸ä¼šé˜»å¡žé¡µé¢ä¸­çš„UIæ¸²æŸ“ï¼Œå› æ­¤éžå¸¸é€‚åˆç”¨æ¥å¤„ç†è€—æ—¶è®¡ç®—æ“ä½œï¼Œå³æ–‡ä»¶çš„**hashè®¡ç®—**ã€‚

### æ–‡ä»¶åˆ†ç‰‡

![file-prototype](http://image.aklry.com/docs/file-prototype.png)

å¦‚å›¾æ‰€ç¤ºï¼ŒFileå¯¹è±¡åŽŸåž‹ä¸º**Blob**ï¼Œå…·å¤‡sliceçš„åˆ†ç‰‡æ–¹æ³•ï¼Œå› æ­¤å¯ä»¥åˆ©ç”¨è¯¥æ–¹æ³•å®žçŽ°æ–‡ä»¶çš„åˆ†ç‰‡ã€‚

~~~js
const uploadBtn = document.getElementById('uploadBtn')
const fileInput = document.getElementById('file')
// åˆ‡ç‰‡å¤§å°10MB
const chunkSize = 1024 * 1024 * 10
const chunks = []
const worker = new Worker('./worker.js')
uploadBtn.addEventListener('click', () => {
	// è¯»å–æ–‡ä»¶å†…å®¹
	const file = fileInput.files[0]
	const { size } = file
	// è®¡ç®—æ€»åˆ‡ç‰‡æ•°
	total = Math.ceil(size / chunkSize)
	chunks.push(...Array.from({ length: total }, (_, i) => file.slice(i * chunkSize, (i + 1) * chunkSize)))
	// å‘ worker çº¿ç¨‹å‘é€æ¶ˆæ¯
	worker.postMessage({
		chunks,
		filename: file.name
	})
})
~~~

~~~js
/**
 * web worker æµè§ˆå™¨çš„å¤šçº¿ç¨‹è„šæœ¬
 * æ˜¯è¿è¡Œåœ¨åŽå°çš„js ä¸ä¼šé˜»å¡žé¡µé¢
 * å¯ä»¥è¿›è¡Œè®¡ç®— å¯ä»¥è¿›è¡Œioæ“ä½œ ä¸èƒ½æ“ä½œDOM
 * ä¸èƒ½è®¿é—®window alert document locationç­‰æµè§ˆå™¨å¯¹è±¡
 * selfä»£è¡¨workerå…¨å±€å¯¹è±¡
 * spark-md5.jsç”¨äºŽè®¡ç®—æ–‡ä»¶çš„å”¯ä¸€hashå€¼
 */
self.importScripts('./utils/spark-md5.js')
self.addEventListener('message', e => {
	const { chunks, filename } = e.data
	// è®¡ç®—md5
	const spark = new self.SparkMD5.ArrayBuffer()
	let current = 0
	function loadNext() {
		const reader = new FileReader()
		reader.onload = e => {
			spark.append(e.target.result)
			current++
			if (current < chunks.length) {
				loadNext()
			} else {
				// å…¨éƒ¨è¯»å–å®Œæ¯• å‘é€ç»“æžœç»™ä¸»çº¿ç¨‹
				self.postMessage({
					filename,
					hash: spark.end()
				})
			}
		}
		reader.readAsArrayBuffer(chunks[current])
	}

	loadNext()
})

~~~

### æ–‡ä»¶ä¸Šä¼ 

~~~js
/**
 * å¤„ç†æ–‡ä»¶ä¸Šä¼ å­˜æ”¾çš„ä½ç½®
 * å¤„ç†æ–‡ä»¶åå­—
 */
const storage = multer.diskStorage({
	destination: (req, file, cb) => {
		fs.mkdirSync(`uploads/${req.body.hash}`, { recursive: true }) // ç¡®ä¿ä¸Šä¼ ç›®å½•å­˜åœ¨
		cb(null, `uploads/${req.body.hash}/`)
	},
	filename: (req, file, cb) => {
		cb(null, `${req.body.filename}-${req.body.index}`) // ä½¿ç”¨hashå€¼å’Œåˆ‡ç‰‡ä¸‹æ ‡ä½œä¸ºæ–‡ä»¶å
	}
})

const upload = multer({ storage })

/**
 * æ–‡ä»¶ä¸Šä¼ æŽ¥å£
 * fileå­—æ®µåéœ€å’Œå‰ç«¯ä¿æŒä¸€è‡´
 */
app.post('/upload', upload.single('file'), (req, res) => {
	res.json({ message: 'File uploaded successfully', success: true })
})
~~~

### åˆ†ç‰‡çš„åˆå¹¶

~~~js
/**
 * åˆå¹¶åˆ‡ç‰‡(é€šè¿‡æ–‡ä»¶æµåˆå¹¶)
 */
app.get('/merge', async (req, res) => {
	const { filename, hash } = req.query
	// èŽ·å–åˆ‡ç‰‡æ‰€åœ¨ç›®å½•
	const files = fs.readdirSync(`uploads/${hash}`)
	// æ ¹æ®indexæŽ’åº
	const fileArraySort = files.sort((a, b) => {
		const indexA = parseInt(a.split('-').pop())
		const indexB = parseInt(b.split('-').pop())
		return indexA - indexB
	})
	// åˆ›å»ºå­˜æ”¾æœ€ç»ˆåˆå¹¶çš„æ–‡ä»¶ ç›®å½•
	const filePath = path.join(__dirname, hash)
	fs.mkdirSync(filePath, { recursive: true })
	// åˆ›å»ºå†™å…¥æµ
	const writeStream = fs.createWriteStream(path.join(filePath, filename))

	for (const file of fileArraySort) {
		await new Promise((resolve, reject) => {
			// åˆ›å»ºè¯»å–æµ(è¯»å–æ¯ä¸€ä¸ªåˆ‡ç‰‡)
			const readStream = fs.createReadStream(path.join(__dirname, 'uploads', hash, file))
			readStream.pipe(writeStream, { end: false }) // ç®¡é“æµå†™å…¥ä½†ä¸å…³é—­å†™å…¥æµ
			readStream.on('end', () => {
				fs.unlinkSync(path.join(__dirname, 'uploads', hash, file)) // åˆ é™¤åˆ‡ç‰‡
				resolve()
			})
			readStream.on('error', reject)
		})
	}
	// æ‰‹åŠ¨å…³é—­
	writeStream.end()
	res.json({
		success: true
	})
})
~~~



## ç§’ä¼ 

**ç§’ä¼ **è¡¨ç¤ºä¸Šä¼ è¿‡çš„æ–‡ä»¶ä¸ä¼šå†æ¬¡ä¸Šä¼ ï¼Œå› æ­¤åªéœ€éªŒè¯æŸä¸ªhashå€¼çš„ç›®å½•æ˜¯å¦å­˜åœ¨**åˆå¹¶åŽ**çš„æ–‡ä»¶å³å¯ã€‚

~~~js
app.get('/verify', (req, res) => {
	const { hash, filename } = req.query
	// åˆ¤æ–­æ˜¯å¦ç§’ä¼ 
	const filePath = path.join(__dirname, hash, filename)
	if (fs.existsSync(filePath)) {
		return res.json({ success: true, fileExist: true })
	}
	return res.json({ success: true, fileExist: false })
})
~~~



## æ–­ç‚¹ç»­ä¼ 

**æ–­ç‚¹ç»­ä¼ **è¡¨ç¤ºå½“ç½‘ç»œä¸­æ–­æ—¶å»¶ç»­è¿‡åŽ»çš„è¿›åº¦ç»§ç»­ä¸Šä¼ ã€‚

~~~js
app.get('/verify', (req, res) => {
	const { hash, filename } = req.query
	// åˆ¤æ–­æ˜¯å¦ç§’ä¼ 
	const filePath = path.join(__dirname, hash, filename)
	if (fs.existsSync(filePath)) {
		return res.json({ success: true, fileExist: true })
	}
	// æ–­ç‚¹ç»­ä¼ (è¿”å›žå·²ä¸Šä¼ çš„æ–‡ä»¶åˆ—è¡¨)
	const isExist = fs.existsSync(path.join(__dirname, 'uploads', hash))
	if (!isExist) {
		return res.json({ success: true, files: [] })
	}
	const files = fs.readdirSync(path.join(__dirname, 'uploads', hash))
	res.json({ success: true, files })
})
~~~

> ðŸŽ‡ç§’ä¼ ä¸Žæ–­ç‚¹ç»­ä¼ éƒ½éœ€è¦åœ¨æ–‡ä»¶ä¸Šä¼ å‰è°ƒç”¨

~~~js
const res = await fetch(`http://localhost:3000/verify?hash=${hash}&filename=${filename}`)
	const { files, fileExist } = await res.json()
	if (fileExist) {
		return
	}
	const uploadedSet = new Set(files)
	const tasks = chunks
		.map((chunk, index) => ({ chunk, index }))
		.filter(({ index }) => !uploadedSet.has(`${filename}-${index}`))
    // æ–‡ä»¶ä¸Šä¼ 
~~~

